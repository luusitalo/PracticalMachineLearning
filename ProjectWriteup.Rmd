---
title: 'Practical Machine Learning Course Project: Writeup'
author: "L Uusitalo"
date: "08/21/2015"
output: html_document
---

#Introduction

This data comes from automatic measurements taken from people doing weight lift exercises in 5 different ways. The goal of this exercise is to predict the how they exercised ("classe" variable, taking values A-E), based on any other variables in the data. You should create a report describing how you built your model, how you used cross validation, what you think the expected out of sample error is, and why you made the choices you did. You will also use your prediction model to predict 20 different test cases. 


#Data aquisition

The data can be aqcuired using this code:
```{r echo=FALSE}
setwd("/home/laurau/CourseraDataScience/PractMachLearning/")
```

```{r}
download.file("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", "training.csv", quiet = FALSE)
download.file("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", "testing.csv", quiet = FALSE)

training<-read.csv("training.csv", na.strings=c("NA",""))
testing<-read.csv("testing.csv", na.strings=c("NA",""))    

```

##Data cleaning

First, remove first 7 columns since they include row numbers, usernames etc that should be irrelevant to the resut and might be misleading: the data is oedered by the class variable, so the row number may become a very good predictor although it may not have nothing to do with the result in the out of training data samples.

The data includes a large number of variables that are mostly NA. While these may potentially be useful predictors, but as the number of predictors is very big, it will be easier to see if the model fit will be good even with fewer variables. Remove variables with > 50 % NA.

```{r}
training<-training[,-c(1:7)]
testing<-testing[,-c(1:7)]

mostly_data<-apply(!is.na(training),2,sum)>(nrow(training)/2)
training<-training[,mostly_data]
testing<-testing[,mostly_data]
```

#Model
A random forest model is fit to the data, using all the other remaining variables as explaining variables.

trainControl is used to define that the algorithm should perform a 10-fold cross-validation to evaluate the out-of-sample error.

```{r cache=TRUE}
library(caret)
set.seed(123)
tr<-trainControl(method="cv",number=10)
fit<-train(classe ~ ., method="rf", data=training, trControl=tr, allowParallel=TRUE)
print(fit)
```

The model gives a very high prediction accuracy (99.5 %), so it can be concluded that the removed variables (those including > 50 % NAs) are not needed to improve the prediction.

#Cross-validation and out of sample error estimate
10-fold cross-validation was performed within the training algorithm to evaluate the out of sample error rate (see the model fit). The confusion matrix shows 81 misclassifications out of 19622, resulting an **estimated out of sample error rate of approximately 0.5 %** (see the output below).

```{r}
print(fit$finalModel)
```

#Discussion

The random forest models was chosen for three main reasons:

* its  good prediction results in many cases

* the fact that it is not sensitive to possible skweness in the data and hence does not require so much pre-processing

* the data includes both numeric and factor variables, and these are morre conveniently handled in a decision tree setting, compared to e.g. regression models.

The variables including > 50 % of NAs were removed to speed up the model fitting process. The data includes a high number of variables and as shown, a smaller number was able to predict the outcome. Removing the index variables was important for the model performance, as the data were ordered by the outcome variable and therefore the row numver was a strong predictor in the training data.